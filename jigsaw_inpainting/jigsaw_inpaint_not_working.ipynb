{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import STL10\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from inpainting import Encoder, Decoder, InpaintingModel, Discriminator, mask_image  # Adjust path if needed\n",
    "from jigsaw import create_jigsaw_puzzle, create_permutations, JigsawResNet, JigsawSTL10Dataset  # Adjust path if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load STL10 dataset\n",
    "train_dataset = STL10(root='./data', split='train+unlabeled', download=True, transform=transform)\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Jigsaw dataset and data loaders\n",
    "jigsaw_train_dataset = JigsawSTL10Dataset(train_dataset)\n",
    "jigsaw_val_dataset = JigsawSTL10Dataset(val_dataset)\n",
    "\n",
    "jigsaw_train_loader = DataLoader(jigsaw_train_dataset, batch_size=64, shuffle=True, num_workers=12)\n",
    "jigsaw_val_loader = DataLoader(jigsaw_val_dataset, batch_size=64, shuffle=False, num_workers=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3045446/1374117004.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using new encoder\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for InpaintingModel:\n\tMissing key(s) in state_dict: \"encoder.encoder.0.weight\", \"encoder.encoder.1.weight\", \"encoder.encoder.1.bias\", \"encoder.encoder.1.running_mean\", \"encoder.encoder.1.running_var\", \"encoder.encoder.4.0.conv1.weight\", \"encoder.encoder.4.0.bn1.weight\", \"encoder.encoder.4.0.bn1.bias\", \"encoder.encoder.4.0.bn1.running_mean\", \"encoder.encoder.4.0.bn1.running_var\", \"encoder.encoder.4.0.conv2.weight\", \"encoder.encoder.4.0.bn2.weight\", \"encoder.encoder.4.0.bn2.bias\", \"encoder.encoder.4.0.bn2.running_mean\", \"encoder.encoder.4.0.bn2.running_var\", \"encoder.encoder.4.1.conv1.weight\", \"encoder.encoder.4.1.bn1.weight\", \"encoder.encoder.4.1.bn1.bias\", \"encoder.encoder.4.1.bn1.running_mean\", \"encoder.encoder.4.1.bn1.running_var\", \"encoder.encoder.4.1.conv2.weight\", \"encoder.encoder.4.1.bn2.weight\", \"encoder.encoder.4.1.bn2.bias\", \"encoder.encoder.4.1.bn2.running_mean\", \"encoder.encoder.4.1.bn2.running_var\", \"encoder.encoder.5.0.conv1.weight\", \"encoder.encoder.5.0.bn1.weight\", \"encoder.encoder.5.0.bn1.bias\", \"encoder.encoder.5.0.bn1.running_mean\", \"encoder.encoder.5.0.bn1.running_var\", \"encoder.encoder.5.0.conv2.weight\", \"encoder.encoder.5.0.bn2.weight\", \"encoder.encoder.5.0.bn2.bias\", \"encoder.encoder.5.0.bn2.running_mean\", \"encoder.encoder.5.0.bn2.running_var\", \"encoder.encoder.5.0.downsample.0.weight\", \"encoder.encoder.5.0.downsample.1.weight\", \"encoder.encoder.5.0.downsample.1.bias\", \"encoder.encoder.5.0.downsample.1.running_mean\", \"encoder.encoder.5.0.downsample.1.running_var\", \"encoder.encoder.5.1.conv1.weight\", \"encoder.encoder.5.1.bn1.weight\", \"encoder.encoder.5.1.bn1.bias\", \"encoder.encoder.5.1.bn1.running_mean\", \"encoder.encoder.5.1.bn1.running_var\", \"encoder.encoder.5.1.conv2.weight\", \"encoder.encoder.5.1.bn2.weight\", \"encoder.encoder.5.1.bn2.bias\", \"encoder.encoder.5.1.bn2.running_mean\", \"encoder.encoder.5.1.bn2.running_var\", \"encoder.encoder.6.0.conv1.weight\", \"encoder.encoder.6.0.bn1.weight\", \"encoder.encoder.6.0.bn1.bias\", \"encoder.encoder.6.0.bn1.running_mean\", \"encoder.encoder.6.0.bn1.running_var\", \"encoder.encoder.6.0.conv2.weight\", \"encoder.encoder.6.0.bn2.weight\", \"encoder.encoder.6.0.bn2.bias\", \"encoder.encoder.6.0.bn2.running_mean\", \"encoder.encoder.6.0.bn2.running_var\", \"encoder.encoder.6.0.downsample.0.weight\", \"encoder.encoder.6.0.downsample.1.weight\", \"encoder.encoder.6.0.downsample.1.bias\", \"encoder.encoder.6.0.downsample.1.running_mean\", \"encoder.encoder.6.0.downsample.1.running_var\", \"encoder.encoder.6.1.conv1.weight\", \"encoder.encoder.6.1.bn1.weight\", \"encoder.encoder.6.1.bn1.bias\", \"encoder.encoder.6.1.bn1.running_mean\", \"encoder.encoder.6.1.bn1.running_var\", \"encoder.encoder.6.1.conv2.weight\", \"encoder.encoder.6.1.bn2.weight\", \"encoder.encoder.6.1.bn2.bias\", \"encoder.encoder.6.1.bn2.running_mean\", \"encoder.encoder.6.1.bn2.running_var\", \"encoder.encoder.7.0.conv1.weight\", \"encoder.encoder.7.0.bn1.weight\", \"encoder.encoder.7.0.bn1.bias\", \"encoder.encoder.7.0.bn1.running_mean\", \"encoder.encoder.7.0.bn1.running_var\", \"encoder.encoder.7.0.conv2.weight\", \"encoder.encoder.7.0.bn2.weight\", \"encoder.encoder.7.0.bn2.bias\", \"encoder.encoder.7.0.bn2.running_mean\", \"encoder.encoder.7.0.bn2.running_var\", \"encoder.encoder.7.0.downsample.0.weight\", \"encoder.encoder.7.0.downsample.1.weight\", \"encoder.encoder.7.0.downsample.1.bias\", \"encoder.encoder.7.0.downsample.1.running_mean\", \"encoder.encoder.7.0.downsample.1.running_var\", \"encoder.encoder.7.1.conv1.weight\", \"encoder.encoder.7.1.bn1.weight\", \"encoder.encoder.7.1.bn1.bias\", \"encoder.encoder.7.1.bn1.running_mean\", \"encoder.encoder.7.1.bn1.running_var\", \"encoder.encoder.7.1.conv2.weight\", \"encoder.encoder.7.1.bn2.weight\", \"encoder.encoder.7.1.bn2.bias\", \"encoder.encoder.7.1.bn2.running_mean\", \"encoder.encoder.7.1.bn2.running_var\", \"decoder.decoder.0.weight\", \"decoder.decoder.0.bias\", \"decoder.decoder.2.weight\", \"decoder.decoder.2.bias\", \"decoder.decoder.4.weight\", \"decoder.decoder.4.bias\", \"decoder.decoder.6.weight\", \"decoder.decoder.6.bias\", \"decoder.decoder.8.weight\", \"decoder.decoder.8.bias\". \n\tUnexpected key(s) in state_dict: \"module.backbone.0.weight\", \"module.backbone.1.weight\", \"module.backbone.1.bias\", \"module.backbone.1.running_mean\", \"module.backbone.1.running_var\", \"module.backbone.1.num_batches_tracked\", \"module.backbone.4.0.conv1.weight\", \"module.backbone.4.0.bn1.weight\", \"module.backbone.4.0.bn1.bias\", \"module.backbone.4.0.bn1.running_mean\", \"module.backbone.4.0.bn1.running_var\", \"module.backbone.4.0.bn1.num_batches_tracked\", \"module.backbone.4.0.conv2.weight\", \"module.backbone.4.0.bn2.weight\", \"module.backbone.4.0.bn2.bias\", \"module.backbone.4.0.bn2.running_mean\", \"module.backbone.4.0.bn2.running_var\", \"module.backbone.4.0.bn2.num_batches_tracked\", \"module.backbone.4.1.conv1.weight\", \"module.backbone.4.1.bn1.weight\", \"module.backbone.4.1.bn1.bias\", \"module.backbone.4.1.bn1.running_mean\", \"module.backbone.4.1.bn1.running_var\", \"module.backbone.4.1.bn1.num_batches_tracked\", \"module.backbone.4.1.conv2.weight\", \"module.backbone.4.1.bn2.weight\", \"module.backbone.4.1.bn2.bias\", \"module.backbone.4.1.bn2.running_mean\", \"module.backbone.4.1.bn2.running_var\", \"module.backbone.4.1.bn2.num_batches_tracked\", \"module.backbone.5.0.conv1.weight\", \"module.backbone.5.0.bn1.weight\", \"module.backbone.5.0.bn1.bias\", \"module.backbone.5.0.bn1.running_mean\", \"module.backbone.5.0.bn1.running_var\", \"module.backbone.5.0.bn1.num_batches_tracked\", \"module.backbone.5.0.conv2.weight\", \"module.backbone.5.0.bn2.weight\", \"module.backbone.5.0.bn2.bias\", \"module.backbone.5.0.bn2.running_mean\", \"module.backbone.5.0.bn2.running_var\", \"module.backbone.5.0.bn2.num_batches_tracked\", \"module.backbone.5.0.downsample.0.weight\", \"module.backbone.5.0.downsample.1.weight\", \"module.backbone.5.0.downsample.1.bias\", \"module.backbone.5.0.downsample.1.running_mean\", \"module.backbone.5.0.downsample.1.running_var\", \"module.backbone.5.0.downsample.1.num_batches_tracked\", \"module.backbone.5.1.conv1.weight\", \"module.backbone.5.1.bn1.weight\", \"module.backbone.5.1.bn1.bias\", \"module.backbone.5.1.bn1.running_mean\", \"module.backbone.5.1.bn1.running_var\", \"module.backbone.5.1.bn1.num_batches_tracked\", \"module.backbone.5.1.conv2.weight\", \"module.backbone.5.1.bn2.weight\", \"module.backbone.5.1.bn2.bias\", \"module.backbone.5.1.bn2.running_mean\", \"module.backbone.5.1.bn2.running_var\", \"module.backbone.5.1.bn2.num_batches_tracked\", \"module.backbone.6.0.conv1.weight\", \"module.backbone.6.0.bn1.weight\", \"module.backbone.6.0.bn1.bias\", \"module.backbone.6.0.bn1.running_mean\", \"module.backbone.6.0.bn1.running_var\", \"module.backbone.6.0.bn1.num_batches_tracked\", \"module.backbone.6.0.conv2.weight\", \"module.backbone.6.0.bn2.weight\", \"module.backbone.6.0.bn2.bias\", \"module.backbone.6.0.bn2.running_mean\", \"module.backbone.6.0.bn2.running_var\", \"module.backbone.6.0.bn2.num_batches_tracked\", \"module.backbone.6.0.downsample.0.weight\", \"module.backbone.6.0.downsample.1.weight\", \"module.backbone.6.0.downsample.1.bias\", \"module.backbone.6.0.downsample.1.running_mean\", \"module.backbone.6.0.downsample.1.running_var\", \"module.backbone.6.0.downsample.1.num_batches_tracked\", \"module.backbone.6.1.conv1.weight\", \"module.backbone.6.1.bn1.weight\", \"module.backbone.6.1.bn1.bias\", \"module.backbone.6.1.bn1.running_mean\", \"module.backbone.6.1.bn1.running_var\", \"module.backbone.6.1.bn1.num_batches_tracked\", \"module.backbone.6.1.conv2.weight\", \"module.backbone.6.1.bn2.weight\", \"module.backbone.6.1.bn2.bias\", \"module.backbone.6.1.bn2.running_mean\", \"module.backbone.6.1.bn2.running_var\", \"module.backbone.6.1.bn2.num_batches_tracked\", \"module.backbone.7.0.conv1.weight\", \"module.backbone.7.0.bn1.weight\", \"module.backbone.7.0.bn1.bias\", \"module.backbone.7.0.bn1.running_mean\", \"module.backbone.7.0.bn1.running_var\", \"module.backbone.7.0.bn1.num_batches_tracked\", \"module.backbone.7.0.conv2.weight\", \"module.backbone.7.0.bn2.weight\", \"module.backbone.7.0.bn2.bias\", \"module.backbone.7.0.bn2.running_mean\", \"module.backbone.7.0.bn2.running_var\", \"module.backbone.7.0.bn2.num_batches_tracked\", \"module.backbone.7.0.downsample.0.weight\", \"module.backbone.7.0.downsample.1.weight\", \"module.backbone.7.0.downsample.1.bias\", \"module.backbone.7.0.downsample.1.running_mean\", \"module.backbone.7.0.downsample.1.running_var\", \"module.backbone.7.0.downsample.1.num_batches_tracked\", \"module.backbone.7.1.conv1.weight\", \"module.backbone.7.1.bn1.weight\", \"module.backbone.7.1.bn1.bias\", \"module.backbone.7.1.bn1.running_mean\", \"module.backbone.7.1.bn1.running_var\", \"module.backbone.7.1.bn1.num_batches_tracked\", \"module.backbone.7.1.conv2.weight\", \"module.backbone.7.1.bn2.weight\", \"module.backbone.7.1.bn2.bias\", \"module.backbone.7.1.bn2.running_mean\", \"module.backbone.7.1.bn2.running_var\", \"module.backbone.7.1.bn2.num_batches_tracked\", \"module.fc.0.weight\", \"module.fc.0.bias\", \"module.fc.2.weight\", \"module.fc.2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/users/soh62/SSL/jigsaw_inpaint/test.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ood.ccv.brown.edu/users/soh62/SSL/jigsaw_inpaint/test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(PATH, map_location\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m      <a href='vscode-notebook-cell://ood.ccv.brown.edu/users/soh62/SSL/jigsaw_inpaint/test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m inpainting_model \u001b[39m=\u001b[39m InpaintingModel()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ood.ccv.brown.edu/users/soh62/SSL/jigsaw_inpaint/test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m inpainting_model\u001b[39m.\u001b[39;49mload_state_dict(checkpoint)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for InpaintingModel:\n\tMissing key(s) in state_dict: \"encoder.encoder.0.weight\", \"encoder.encoder.1.weight\", \"encoder.encoder.1.bias\", \"encoder.encoder.1.running_mean\", \"encoder.encoder.1.running_var\", \"encoder.encoder.4.0.conv1.weight\", \"encoder.encoder.4.0.bn1.weight\", \"encoder.encoder.4.0.bn1.bias\", \"encoder.encoder.4.0.bn1.running_mean\", \"encoder.encoder.4.0.bn1.running_var\", \"encoder.encoder.4.0.conv2.weight\", \"encoder.encoder.4.0.bn2.weight\", \"encoder.encoder.4.0.bn2.bias\", \"encoder.encoder.4.0.bn2.running_mean\", \"encoder.encoder.4.0.bn2.running_var\", \"encoder.encoder.4.1.conv1.weight\", \"encoder.encoder.4.1.bn1.weight\", \"encoder.encoder.4.1.bn1.bias\", \"encoder.encoder.4.1.bn1.running_mean\", \"encoder.encoder.4.1.bn1.running_var\", \"encoder.encoder.4.1.conv2.weight\", \"encoder.encoder.4.1.bn2.weight\", \"encoder.encoder.4.1.bn2.bias\", \"encoder.encoder.4.1.bn2.running_mean\", \"encoder.encoder.4.1.bn2.running_var\", \"encoder.encoder.5.0.conv1.weight\", \"encoder.encoder.5.0.bn1.weight\", \"encoder.encoder.5.0.bn1.bias\", \"encoder.encoder.5.0.bn1.running_mean\", \"encoder.encoder.5.0.bn1.running_var\", \"encoder.encoder.5.0.conv2.weight\", \"encoder.encoder.5.0.bn2.weight\", \"encoder.encoder.5.0.bn2.bias\", \"encoder.encoder.5.0.bn2.running_mean\", \"encoder.encoder.5.0.bn2.running_var\", \"encoder.encoder.5.0.downsample.0.weight\", \"encoder.encoder.5.0.downsample.1.weight\", \"encoder.encoder.5.0.downsample.1.bias\", \"encoder.encoder.5.0.downsample.1.running_mean\", \"encoder.encoder.5.0.downsample.1.running_var\", \"encoder.encoder.5.1.conv1.weight\", \"encoder.encoder.5.1.bn1.weight\", \"encoder.encoder.5.1.bn1.bias\", \"encoder.encoder.5.1.bn1.running_mean\", \"encoder.encoder.5.1.bn1.running_var\", \"encoder.encoder.5.1.conv2.weight\", \"encoder.encoder.5.1.bn2.weight\", \"encoder.encoder.5.1.bn2.bias\", \"encoder.encoder.5.1.bn2.running_mean\", \"encoder.encoder.5.1.bn2.running_var\", \"encoder.encoder.6.0.conv1.weight\", \"encoder.encoder.6.0.bn1.weight\", \"encoder.encoder.6.0.bn1.bias\", \"encoder.encoder.6.0.bn1.running_mean\", \"encoder.encoder.6.0.bn1.running_var\", \"encoder.encoder.6.0.conv2.weight\", \"encoder.encoder.6.0.bn2.weight\", \"encoder.encoder.6.0.bn2.bias\", \"encoder.encoder.6.0.bn2.running_mean\", \"encoder.encoder.6.0.bn2.running_var\", \"encoder.encoder.6.0.downsample.0.weight\", \"encoder.encoder.6.0.downsample.1.weight\", \"encoder.encoder.6.0.downsample.1.bias\", \"encoder.encoder.6.0.downsample.1.running_mean\", \"encoder.encoder.6.0.downsample.1.running_var\", \"encoder.encoder.6.1.conv1.weight\", \"encoder.encoder.6.1.bn1.weight\", \"encoder.encoder.6.1.bn1.bias\", \"encoder.encoder.6.1.bn1.running_mean\", \"encoder.encoder.6.1.bn1.running_var\", \"encoder.encoder.6.1.conv2.weight\", \"encoder.encoder.6.1.bn2.weight\", \"encoder.encoder.6.1.bn2.bias\", \"encoder.encoder.6.1.bn2.running_mean\", \"encoder.encoder.6.1.bn2.running_var\", \"encoder.encoder.7.0.conv1.weight\", \"encoder.encoder.7.0.bn1.weight\", \"encoder.encoder.7.0.bn1.bias\", \"encoder.encoder.7.0.bn1.running_mean\", \"encoder.encoder.7.0.bn1.running_var\", \"encoder.encoder.7.0.conv2.weight\", \"encoder.encoder.7.0.bn2.weight\", \"encoder.encoder.7.0.bn2.bias\", \"encoder.encoder.7.0.bn2.running_mean\", \"encoder.encoder.7.0.bn2.running_var\", \"encoder.encoder.7.0.downsample.0.weight\", \"encoder.encoder.7.0.downsample.1.weight\", \"encoder.encoder.7.0.downsample.1.bias\", \"encoder.encoder.7.0.downsample.1.running_mean\", \"encoder.encoder.7.0.downsample.1.running_var\", \"encoder.encoder.7.1.conv1.weight\", \"encoder.encoder.7.1.bn1.weight\", \"encoder.encoder.7.1.bn1.bias\", \"encoder.encoder.7.1.bn1.running_mean\", \"encoder.encoder.7.1.bn1.running_var\", \"encoder.encoder.7.1.conv2.weight\", \"encoder.encoder.7.1.bn2.weight\", \"encoder.encoder.7.1.bn2.bias\", \"encoder.encoder.7.1.bn2.running_mean\", \"encoder.encoder.7.1.bn2.running_var\", \"decoder.decoder.0.weight\", \"decoder.decoder.0.bias\", \"decoder.decoder.2.weight\", \"decoder.decoder.2.bias\", \"decoder.decoder.4.weight\", \"decoder.decoder.4.bias\", \"decoder.decoder.6.weight\", \"decoder.decoder.6.bias\", \"decoder.decoder.8.weight\", \"decoder.decoder.8.bias\". \n\tUnexpected key(s) in state_dict: \"module.backbone.0.weight\", \"module.backbone.1.weight\", \"module.backbone.1.bias\", \"module.backbone.1.running_mean\", \"module.backbone.1.running_var\", \"module.backbone.1.num_batches_tracked\", \"module.backbone.4.0.conv1.weight\", \"module.backbone.4.0.bn1.weight\", \"module.backbone.4.0.bn1.bias\", \"module.backbone.4.0.bn1.running_mean\", \"module.backbone.4.0.bn1.running_var\", \"module.backbone.4.0.bn1.num_batches_tracked\", \"module.backbone.4.0.conv2.weight\", \"module.backbone.4.0.bn2.weight\", \"module.backbone.4.0.bn2.bias\", \"module.backbone.4.0.bn2.running_mean\", \"module.backbone.4.0.bn2.running_var\", \"module.backbone.4.0.bn2.num_batches_tracked\", \"module.backbone.4.1.conv1.weight\", \"module.backbone.4.1.bn1.weight\", \"module.backbone.4.1.bn1.bias\", \"module.backbone.4.1.bn1.running_mean\", \"module.backbone.4.1.bn1.running_var\", \"module.backbone.4.1.bn1.num_batches_tracked\", \"module.backbone.4.1.conv2.weight\", \"module.backbone.4.1.bn2.weight\", \"module.backbone.4.1.bn2.bias\", \"module.backbone.4.1.bn2.running_mean\", \"module.backbone.4.1.bn2.running_var\", \"module.backbone.4.1.bn2.num_batches_tracked\", \"module.backbone.5.0.conv1.weight\", \"module.backbone.5.0.bn1.weight\", \"module.backbone.5.0.bn1.bias\", \"module.backbone.5.0.bn1.running_mean\", \"module.backbone.5.0.bn1.running_var\", \"module.backbone.5.0.bn1.num_batches_tracked\", \"module.backbone.5.0.conv2.weight\", \"module.backbone.5.0.bn2.weight\", \"module.backbone.5.0.bn2.bias\", \"module.backbone.5.0.bn2.running_mean\", \"module.backbone.5.0.bn2.running_var\", \"module.backbone.5.0.bn2.num_batches_tracked\", \"module.backbone.5.0.downsample.0.weight\", \"module.backbone.5.0.downsample.1.weight\", \"module.backbone.5.0.downsample.1.bias\", \"module.backbone.5.0.downsample.1.running_mean\", \"module.backbone.5.0.downsample.1.running_var\", \"module.backbone.5.0.downsample.1.num_batches_tracked\", \"module.backbone.5.1.conv1.weight\", \"module.backbone.5.1.bn1.weight\", \"module.backbone.5.1.bn1.bias\", \"module.backbone.5.1.bn1.running_mean\", \"module.backbone.5.1.bn1.running_var\", \"module.backbone.5.1.bn1.num_batches_tracked\", \"module.backbone.5.1.conv2.weight\", \"module.backbone.5.1.bn2.weight\", \"module.backbone.5.1.bn2.bias\", \"module.backbone.5.1.bn2.running_mean\", \"module.backbone.5.1.bn2.running_var\", \"module.backbone.5.1.bn2.num_batches_tracked\", \"module.backbone.6.0.conv1.weight\", \"module.backbone.6.0.bn1.weight\", \"module.backbone.6.0.bn1.bias\", \"module.backbone.6.0.bn1.running_mean\", \"module.backbone.6.0.bn1.running_var\", \"module.backbone.6.0.bn1.num_batches_tracked\", \"module.backbone.6.0.conv2.weight\", \"module.backbone.6.0.bn2.weight\", \"module.backbone.6.0.bn2.bias\", \"module.backbone.6.0.bn2.running_mean\", \"module.backbone.6.0.bn2.running_var\", \"module.backbone.6.0.bn2.num_batches_tracked\", \"module.backbone.6.0.downsample.0.weight\", \"module.backbone.6.0.downsample.1.weight\", \"module.backbone.6.0.downsample.1.bias\", \"module.backbone.6.0.downsample.1.running_mean\", \"module.backbone.6.0.downsample.1.running_var\", \"module.backbone.6.0.downsample.1.num_batches_tracked\", \"module.backbone.6.1.conv1.weight\", \"module.backbone.6.1.bn1.weight\", \"module.backbone.6.1.bn1.bias\", \"module.backbone.6.1.bn1.running_mean\", \"module.backbone.6.1.bn1.running_var\", \"module.backbone.6.1.bn1.num_batches_tracked\", \"module.backbone.6.1.conv2.weight\", \"module.backbone.6.1.bn2.weight\", \"module.backbone.6.1.bn2.bias\", \"module.backbone.6.1.bn2.running_mean\", \"module.backbone.6.1.bn2.running_var\", \"module.backbone.6.1.bn2.num_batches_tracked\", \"module.backbone.7.0.conv1.weight\", \"module.backbone.7.0.bn1.weight\", \"module.backbone.7.0.bn1.bias\", \"module.backbone.7.0.bn1.running_mean\", \"module.backbone.7.0.bn1.running_var\", \"module.backbone.7.0.bn1.num_batches_tracked\", \"module.backbone.7.0.conv2.weight\", \"module.backbone.7.0.bn2.weight\", \"module.backbone.7.0.bn2.bias\", \"module.backbone.7.0.bn2.running_mean\", \"module.backbone.7.0.bn2.running_var\", \"module.backbone.7.0.bn2.num_batches_tracked\", \"module.backbone.7.0.downsample.0.weight\", \"module.backbone.7.0.downsample.1.weight\", \"module.backbone.7.0.downsample.1.bias\", \"module.backbone.7.0.downsample.1.running_mean\", \"module.backbone.7.0.downsample.1.running_var\", \"module.backbone.7.0.downsample.1.num_batches_tracked\", \"module.backbone.7.1.conv1.weight\", \"module.backbone.7.1.bn1.weight\", \"module.backbone.7.1.bn1.bias\", \"module.backbone.7.1.bn1.running_mean\", \"module.backbone.7.1.bn1.running_var\", \"module.backbone.7.1.bn1.num_batches_tracked\", \"module.backbone.7.1.conv2.weight\", \"module.backbone.7.1.bn2.weight\", \"module.backbone.7.1.bn2.bias\", \"module.backbone.7.1.bn2.running_mean\", \"module.backbone.7.1.bn2.running_var\", \"module.backbone.7.1.bn2.num_batches_tracked\", \"module.fc.0.weight\", \"module.fc.0.bias\", \"module.fc.2.weight\", \"module.fc.2.bias\". "
     ]
    }
   ],
   "source": [
    "# Load inpainting model as the base, modified to include jigsaw functionality\n",
    "PATH = 'stl_jigsaw_model.pth' \n",
    "checkpoint = torch.load(PATH, map_location=device)\n",
    "inpainting_model = InpaintingModel().to(device)\n",
    "inpainting_model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Encoder from InpaintingModel in JigsawResNet\n",
    "backbone = inpainting_model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the JigsawResNet model using the inpainting model's encoder\n",
    "num_patches = 9\n",
    "num_permutations = 1000\n",
    "jigsaw_model = JigsawResNet(num_patches=num_patches, num_permutations=num_permutations)\n",
    "jigsaw_model.backbone = backbone  # Set inpainting backbone to jigsaw model\n",
    "jigsaw_model = jigsaw_model.to(device)\n",
    "\n",
    "# Early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.0001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Classification model using JigsawResNet backbone\n",
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self, backbone, num_classes):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        pooled_features = nn.AdaptiveAvgPool2d((1, 1))(features)\n",
    "        pooled_features = pooled_features.view(pooled_features.size(0), -1)\n",
    "        output = self.classifier(pooled_features)\n",
    "        return output\n",
    "\n",
    "classification_model = ClassificationNet(jigsaw_model.backbone, num_classes=10).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation loop setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classification_model.parameters(), lr=1e-3)\n",
    "early_stop = EarlyStopping(patience=15, min_delta=0.000001)\n",
    "num_epochs = 150\n",
    "\n",
    "best_model_weights = classification_model.state_dict()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    classification_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in jigsaw_train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classification_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(jigsaw_train_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    classification_model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_labels in jigsaw_val_loader:\n",
    "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "            val_outputs = classification_model(val_images)\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(jigsaw_val_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    early_stop(avg_val_loss)\n",
    "    if early_stop.early_stop:\n",
    "        print(\"Early stopping due to no improvement in validation loss.\")\n",
    "        break\n",
    "\n",
    "    # Save best model based on validation loss\n",
    "    if avg_val_loss < early_stop.best_loss:\n",
    "        best_model_weights = classification_model.state_dict()\n",
    "\n",
    "        # Ensure directory structure exists\n",
    "        os.makedirs('models/downstream', exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        model_path = f'models/downstream/classification_model_weights_epoch_{epoch+1}.pth'\n",
    "        torch.save(classification_model.state_dict(), model_path)\n",
    "        print(f\"Model saved at Epoch {epoch + 1}\")\n",
    "\n",
    "# Final model saving\n",
    "torch.save(classification_model.state_dict(), 'models/downstream/classification_model_weights_final.pth')\n",
    "torch.save(best_model_weights, 'models/downstream/classification_best_model_weights_final.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
